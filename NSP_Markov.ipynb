{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np \n",
                "import requests\n",
                "import os\n",
                "import re"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Download Data\n",
                "Check if the dataset exists locally, if not, download it from the repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download the file if it doesn't exist\n",
                "if not os.path.exists(\"NUTUK_1.txt\"):\n",
                "    url = \"https://raw.githubusercontent.com/mehmetaksoy/Nutuk-Turkce-NLP-Dataset/main/NUTUK_1.txt\"\n",
                "    response = requests.get(url)\n",
                "\n",
                "    if response.status_code == 200:\n",
                "        with open(\"NUTUK_1.txt\", \"w\", encoding=\"utf-8\") as file:\n",
                "            file.write(response.text)\n",
                "    else:\n",
                "        print(\"Failed to get the file ...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data\n",
                "Read the file and skip the preamble (header information), starting from line 283."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the file and use content starting from line 283\n",
                "with open(\"NUTUK_1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
                "    lines = file.readlines()\n",
                "\n",
                "# Python lists are 0-indexed, so line 283 is at index 282\n",
                "start_line_index = 282\n",
                "nutuk = \"\"\n",
                "\n",
                "if len(lines) > start_line_index:\n",
                "    # Join the lines starting from index 282 to the end\n",
                "    nutuk = \"\".join(lines[start_line_index:])\n",
                "    print(f\"Loaded text starting from line {start_line_index + 1} (Original Line 283)\")\n",
                "    print(\"-\" * 30)\n",
                "    print(\"Preview of the text:\")\n",
                "    print(nutuk[:200]) # Print first 200 chars to verify\n",
                "    print(\"-\" * 30)\n",
                "else:\n",
                "    print(f\"Error: The file has fewer than {start_line_index + 1} lines.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning\n",
                "Lowercase the text, remove punctuation, and split into tokens (words)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. CLEANING THE TEXT\n",
                "if nutuk:\n",
                "    # Convert to lowercase\n",
                "    nutuk_cleaned = nutuk.lower()\n",
                "\n",
                "    # Remove punctuation/special characters (keep distinct Turkish characters if needed, but remove symbols)\n",
                "    # This regex removes anything that is NOT a word character or whitespace.\n",
                "    # \\w includes alphanumeric characters (and underscores).\n",
                "    nutuk_cleaned = re.sub(r'[^\\w\\s]', '', nutuk_cleaned)\n",
                "\n",
                "    # Replace newlines with spaces to treat the whole text as a continuous stream\n",
                "    nutuk_cleaned = nutuk_cleaned.replace('\\n', ' ')\n",
                "\n",
                "    # Split into words (tokens)\n",
                "    words = nutuk_cleaned.split()\n",
                "\n",
                "    print(f\"Total words found: {len(words)}\")\n",
                "    print(\"-\" * 30)\n",
                "    print(\"First 50 words:\")\n",
                "    print(words[:50])\n",
                "    print(\"-\" * 30)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}