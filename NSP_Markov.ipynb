{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a1567155",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np \n",
                "import requests\n",
                "import os\n",
                "import re"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "963568c1",
            "metadata": {},
            "source": [
                "## 1. Download Data\n",
                "Check if the dataset exists locally, if not, download it from the repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "15866295",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download the file if it doesn't exist\n",
                "if not os.path.exists(\"NUTUK_1.txt\"):\n",
                "    url = \"https://raw.githubusercontent.com/mehmetaksoy/Nutuk-Turkce-NLP-Dataset/main/NUTUK_1.txt\"\n",
                "    response = requests.get(url)\n",
                "\n",
                "    if response.status_code == 200:\n",
                "        with open(\"NUTUK_1.txt\", \"w\", encoding=\"utf-8\") as file:\n",
                "            file.write(response.text)\n",
                "    else:\n",
                "        print(\"Failed to get the file ...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3456a758",
            "metadata": {},
            "source": [
                "## 2. Load Data\n",
                "Read the file and skip the preamble (header information), starting from line 283."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "50d59d82",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded text starting from line 283 (Original Line 283)\n",
                        "------------------------------\n",
                        "Preview of the text:\n",
                        "NUTUK 1\n",
                        "(1919-1920) \n",
                        "Samsun'a çıktığım gün genel vaziyet ve manzara\n",
                        "1919 senesi Mayıs'ının 19. günü Samsun'a çıktım. Genel vaziyet ve manzara: \n",
                        "Osmanlı Devleti'nin dahil bulunduğu grup, Harbi Umumi'de\n",
                        "------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Read the file and use content starting from line 283\n",
                "with open(\"NUTUK_1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
                "    lines = file.readlines()\n",
                "\n",
                "# Python lists are 0-indexed, so line 283 is at index 282\n",
                "start_line_index = 282\n",
                "nutuk = \"\"\n",
                "\n",
                "if len(lines) > start_line_index:\n",
                "    # Join the lines starting from index 282 to the end\n",
                "    nutuk = \"\".join(lines[start_line_index:])\n",
                "    print(f\"Loaded text starting from line {start_line_index + 1} (Original Line 283)\")\n",
                "    print(\"-\" * 30)\n",
                "    print(\"Preview of the text:\")\n",
                "    print(nutuk[:200]) # Print first 200 chars to verify\n",
                "    print(\"-\" * 30)\n",
                "else:\n",
                "    print(f\"Error: The file has fewer than {start_line_index + 1} lines.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d74e7d0f",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning\n",
                "Lowercase the text, remove punctuation, and split into tokens (words)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "b6ff2e30",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. CLEANING THE TEXT\n",
                "if nutuk:\n",
                "    # Convert to lowercase\n",
                "    nutuk_cleaned = nutuk.lower()\n",
                "\n",
                "    # Add space around punctuation to preserve them as tokens\n",
                "    nutuk_cleaned = re.sub(r'([.,!?;])', r' \\1 ', nutuk_cleaned)\n",
                "\n",
                "    # Remove punctuation/special characters (keep distinct Turkish characters if needed, but remove symbols)\n",
                "    # This regex removes anything that is NOT a word character or whitespace.\n",
                "    # \\w includes alphanumeric characters (and underscores).\n",
                "    nutuk_cleaned = re.sub(r'[^\\w\\s.,!?;]', '', nutuk_cleaned)\n",
                "\n",
                "    # Replace newlines with spaces to treat the whole text as a continuous stream\n",
                "    nutuk_cleaned = nutuk_cleaned.replace('\\n', ' ')\n",
                "\n",
                "    # Split into words (tokens)\n",
                "    words = nutuk_cleaned.split()\n",
                "\n",
                "    print(f\"Total words found: {len(words)}\")\n",
                "    print(\"-\" * 30)\n",
                "    print(\"First 50 words:\")\n",
                "    print(words[:50])\n",
                "    print(\"-\" * 30)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "50e51f8a",
            "metadata": {},
            "source": [
                "## 4. Build Markov Model\n",
                "Create the vocabulary and the transition matrix (counts of next words)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "480260ad",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define N-Gram Markov Chain Class\n",
                "class MarkovChain:\n",
                "    def __init__(self, words, max_order=3):\n",
                "        self.words = words\n",
                "        self.max_order = max_order\n",
                "        self.vocab = sorted(list(set(self.words)))\n",
                "        self.vocab_size = len(self.vocab)\n",
                "        self.word_to_index = {word: i for i, word in enumerate(self.vocab)}\n",
                "        self.index_to_word = {i: word for i, word in enumerate(self.vocab)}\n",
                "        self.models = {}\n",
                "        self._build_model()\n",
                "\n",
                "    def _build_model(self):\n",
                "        # Build models for orders 1 to max_order\n",
                "        for n in range(1, self.max_order + 1):\n",
                "            self.models[n] = {}\n",
                "            for i in range(len(self.words) - n):\n",
                "                state = tuple(self.words[i:i+n])\n",
                "                next_word = self.words[i+n]\n",
                "                if state not in self.models[n]:\n",
                "                    self.models[n][state] = {}\n",
                "                if next_word not in self.models[n][state]:\n",
                "                    self.models[n][state][next_word] = 0\n",
                "                self.models[n][state][next_word] += 1\n",
                "        print(f\"Models built up to order {self.max_order}\")\n",
                "\n",
                "    def _get_transition_probs(self, history, alpha=0.001):\n",
                "         # Backoff strategy\n",
                "        found_transitions = None\n",
                "        for n in range(min(len(history), self.max_order), 0, -1):\n",
                "            state = tuple(history[-n:])\n",
                "            if state in self.models[n]:\n",
                "                found_transitions = self.models[n][state]\n",
                "                break\n",
                "\n",
                "        if found_transitions is None:\n",
                "             probs = np.ones(self.vocab_size) / self.vocab_size\n",
                "             return probs, None\n",
                "\n",
                "        # Calculate probs with smoothing\n",
                "        probs = np.full(self.vocab_size, alpha)\n",
                "        if found_transitions:\n",
                "            for next_word, count in found_transitions.items():\n",
                "                if next_word in self.word_to_index:\n",
                "                    probs[self.word_to_index[next_word]] += count\n",
                "\n",
                "        return probs / np.sum(probs), found_transitions\n",
                "\n",
                "    def get_next_word(self, history, temperature=1.0, alpha=0.001):\n",
                "        probs, _ = self._get_transition_probs(history, alpha)\n",
                "        \n",
                "        # Handle very low temperature (deterministic / argmax) to avoid numerical instability\n",
                "        if temperature < 0.05:\n",
                "            next_word_idx = np.argmax(probs)\n",
                "            return self.index_to_word[next_word_idx]\n",
                "\n",
                "        if temperature != 1.0:\n",
                "            probs = np.power(probs, 1.0 / temperature)\n",
                "            probs = probs / np.sum(probs)\n",
                "\n",
                "        next_idx = np.random.choice(range(self.vocab_size), p=probs)\n",
                "        return self.index_to_word[next_idx]\n",
                "\n",
                "    def generate_text(self, start_text, length=20, temperature=1.0, alpha=0.001):\n",
                "        # Preprocess start text to respect new punctuation tokens\n",
                "        processed_start = start_text.lower()\n",
                "        processed_start = re.sub(r'([.,!?;])', r' \\1 ', processed_start)\n",
                "        processed_start = re.sub(r'[^\\w\\s.,!?;]', '', processed_start)\n",
                "        processed_start = processed_start.replace('\\n', ' ')\n",
                "        current_history = processed_start.split()\n",
                "        \n",
                "        if not current_history:\n",
                "             return \"\"\n",
                "        result = list(current_history)\n",
                "        for _ in range(length):\n",
                "            next_word = self.get_next_word(current_history, temperature, alpha)\n",
                "            result.append(next_word)\n",
                "            current_history.append(next_word)\n",
                "        return \" \".join(result)\n",
                "\n",
                "print(\"MarkovChain Class defined successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2cc5e691",
            "metadata": {},
            "source": [
                "## 5. Prediction Function\n",
                "Implement `get_next_word` with **Laplace Smoothing** and **Temperature**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "9577fba9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Model\n",
                "max_order = 3\n",
                "model = MarkovChain(words, max_order=max_order)\n",
                "print(f\"Markov Model initiated with Order {max_order}.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0794068c",
            "metadata": {},
            "source": [
                "## 6. Generate Text\n",
                "Let's test the model with different temperatures."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "40533961",
            "metadata": {},
            "outputs": [],
            "source": [
                "start_text = \"millet ve\"\n",
                "\n",
                "print(f\"--- Temp 0.5 (Balanced) ---\")\n",
                "print(model.generate_text(start_text, length=15, temperature=0.5))\n",
                "\n",
                "print(f\"\\n--- Temp 0.9 (Creative) ---\")\n",
                "print(model.generate_text(start_text, length=15, temperature=0.9))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6ecb12e8",
            "metadata": {},
            "source": [
                "## 7. Visualize Transition Probabilities\n",
                "We use bar charts to show the most likely next-words for a few selected terms. This makes filtering easier to interpret than a sparse heatmap."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "e95afa4e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "def visualize_transitions(history, ax=None):\n",
                "    # Use the model's logic to get probs directly\n",
                "    if isinstance(history, str):\n",
                "        history = history.lower().split()\n",
                "        # Handle punctuation in visualization context too if needed\n",
                "        history = re.sub(r'([.,!?;])', r' \\1 ', history)\n",
                "        history = re.sub(r'[^\\w\\s.,!?;]', '', history)\n",
                "        history = history.split()\n",
                "        \n",
                "    probs, _ = model._get_transition_probs(history)\n",
                "    \n",
                "    top_indices = np.argsort(probs)[-5:][::-1]\n",
                "    top_words = [model.index_to_word[idx] for idx in top_indices]\n",
                "    top_probs = [probs[idx] for idx in top_indices]\n",
                "    \n",
                "    if ax is None:\n",
                "        fig, ax = plt.subplots(figsize=(10, 5))\n",
                "        \n",
                "    sns.barplot(x=top_probs, y=top_words, ax=ax, palette=\"viridis\")\n",
                "    context_str = \" \".join(history[-3:]) # Show last few words\n",
                "    ax.set_title(f\"Next words after: '...{context_str}'\")\n",
                "    ax.set_xlabel(\"Probability\")\n",
                "\n",
                "# Demo\n",
                "contexts = [\"millet\", \"türk milleti\", \"büyük millet\", \"ordu ve\", \"vatan\"]\n",
                "fig, axes = plt.subplots(len(contexts), 1, figsize=(10, 3 * len(contexts)))\n",
                "plt.subplots_adjust(hspace=0.5)\n",
                "\n",
                "for i, ctx in enumerate(contexts):\n",
                "    ax = axes[i] if len(contexts) > 1 else axes\n",
                "    visualize_transitions(ctx, ax=ax)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9f356dae",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}